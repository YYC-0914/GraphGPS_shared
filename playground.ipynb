{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"MLP with linear output\"\"\"\n",
    "    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):\n",
    "\n",
    "        super().__init__()\n",
    "        self.linear_or_not = True  # default is linear model\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        if num_layers < 1:\n",
    "            raise ValueError(\"number of layers should be positive!\")\n",
    "        elif num_layers == 1:\n",
    "            # Linear model\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "        else:\n",
    "            # Multi-layer model\n",
    "            self.linear_or_not = False\n",
    "            self.linears = torch.nn.ModuleList()\n",
    "            self.batch_norms = torch.nn.ModuleList()\n",
    "\n",
    "            self.linears.append(nn.Linear(input_dim, hidden_dim))\n",
    "            for layer in range(num_layers - 2):\n",
    "                self.linears.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.linears.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "            for layer in range(num_layers - 1):\n",
    "                self.batch_norms.append(nn.BatchNorm1d((hidden_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.linear_or_not:\n",
    "            # If linear model\n",
    "            return self.linear(x)\n",
    "        else:\n",
    "            # If MLP\n",
    "            h = x\n",
    "            for i in range(self.num_layers - 1):\n",
    "                h = F.relu(self.batch_norms[i](self.linears[i](h)))\n",
    "            return self.linears[-1](h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "class GINEConvESLapPE(pyg_nn.conv.MessagePassing):\n",
    "    \"\"\"GINEConv Layer with EquivStableLapPE implementation.\n",
    "\n",
    "    Modified torch_geometric.nn.conv.GINEConv layer to perform message scaling\n",
    "    according to equiv. stable PEG-layer with Laplacian Eigenmap (LapPE):\n",
    "        ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj\n",
    "    \"\"\"\n",
    "    def __init__(self, nn, eps=0., train_eps=False, edge_dim=None, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(**kwargs)\n",
    "        self.nn = nn\n",
    "        self.initial_eps = eps\n",
    "        if train_eps:\n",
    "            self.eps = torch.nn.Parameter(torch.Tensor([eps]))\n",
    "        else:\n",
    "            self.register_buffer('eps', torch.Tensor([eps]))\n",
    "        if edge_dim is not None:\n",
    "            if hasattr(self.nn[0], 'in_features'):\n",
    "                in_channels = self.nn[0].in_features\n",
    "            else:\n",
    "                in_channels = self.nn[0].in_channels\n",
    "            self.lin = pyg_nn.Linear(edge_dim, in_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "        if hasattr(self.nn[0], 'in_features'):\n",
    "            out_dim = self.nn[0].out_features\n",
    "        else:\n",
    "            out_dim = self.nn[0].out_channels\n",
    "        print(\"out dimension: \", out_dim)\n",
    "        # Handling for Equivariant and Stable PE using LapPE\n",
    "        # ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj\n",
    "        self.mlp_r_ij = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, out_dim), torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_dim, 1),\n",
    "            torch.nn.Sigmoid())\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pyg_nn.inits.reset(self.nn)\n",
    "        self.eps.data.fill_(self.initial_eps)\n",
    "        if self.lin is not None:\n",
    "            self.lin.reset_parameters()\n",
    "        pyg_nn.inits.reset(self.mlp_r_ij)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None, pe_LapPE=None, size=None):\n",
    "        # if isinstance(x, Tensor):\n",
    "        #     x: OptPairTensor = (x, x)\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr,\n",
    "                             PE=pe_LapPE, size=size)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if x_r is not None:\n",
    "            out += (1 + self.eps) * x_r\n",
    "\n",
    "        return self.nn(out)\n",
    "\n",
    "    def message(self, x_j, edge_attr, PE_i, PE_j):\n",
    "        if self.lin is None and x_j.size(-1) != edge_attr.size(-1):\n",
    "            raise ValueError(\"Node and edge feature dimensionalities do not \"\n",
    "                             \"match. Consider setting the 'edge_dim' \"\n",
    "                             \"attribute of 'GINEConv'\")\n",
    "\n",
    "        if self.lin is not None:\n",
    "            edge_attr = self.lin(edge_attr)\n",
    "\n",
    "        # Handling for Equivariant and Stable PE using LapPE\n",
    "        # ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj\n",
    "        r_ij = ((PE_i - PE_j) ** 2).sum(dim=-1, keepdim=True)\n",
    "        r_ij = self.mlp_r_ij(r_ij)  # the MLP is 1 dim --> hidden_dim --> 1 dim\n",
    "\n",
    "        return ((x_j + edge_attr).relu()) * r_ij\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(nn={self.nn})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out dimension:  64\n",
      "Number of parameters: 8513\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import Linear as Linear_pyg\n",
    "import torch.nn.functional as F\n",
    "hidden_dim = 64\n",
    "gineconvlayer = GINEConvESLapPE(nn.Sequential(Linear_pyg(hidden_dim, hidden_dim),\n",
    "                                   nn.ReLU(), \n",
    "                                   Linear_pyg(hidden_dim, hidden_dim)))\n",
    "total_params = sum(p.numel() for p in gineconvlayer.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Linear as Linear_pyg\n",
    "import torch.nn.functional as F\n",
    "class VGNLayer(nn.Module):\n",
    "    def __init__(self, num_clusters, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.num_clusters = num_clusters\n",
    "        self.model = nn.ModuleList()\n",
    "        for _ in range(num_clusters):\n",
    "            gin_nn = nn.Sequential(Linear_pyg(hidden_dim, hidden_dim),\n",
    "                                   nn.ReLU(), \n",
    "                                   Linear_pyg(hidden_dim, hidden_dim))\n",
    "            self.model.append(GINEConvESLapPE(gin_nn))\n",
    "\n",
    "    def forward(self, x, masks, edge_index, edge_attr=None, pe_LapPE=None, size=None):\n",
    "        x_in = x\n",
    "        for cluster in range(self.num_clusters): \n",
    "            x_tmp = x.clone()\n",
    "            x = self.model[cluster](x, edge_index, edge_attr, pe_LapPE)\n",
    "            x = torch.einsum('i,ij->ij', masks[cluster], x) + x_tmp\n",
    "        \n",
    "            if self.batch_norm:\n",
    "                x = self.bn[cluster](x)\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        if self.residual:\n",
    "            x = x_in + x\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out dimension:  64\n",
      "out dimension:  64\n",
      "out dimension:  64\n",
      "Number of parameters: 25539\n"
     ]
    }
   ],
   "source": [
    "model = VGNLayer(3, 64)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP output:  tensor([[ 0.7243,  1.6338,  0.6300],\n",
      "        [-0.3052, -0.4431, -0.1276],\n",
      "        [-0.4478, -0.8402, -0.3304],\n",
      "        [ 1.2718, -1.4993, -0.6587],\n",
      "        [ 0.6263,  0.0116, -0.2667],\n",
      "        [-0.6787, -0.1957,  0.9593],\n",
      "        [-0.5144, -1.3066, -1.5799],\n",
      "        [ 0.0691, -0.4715, -1.1053],\n",
      "        [-0.7641, -2.1179, -0.1819],\n",
      "        [ 1.5850,  0.8496,  1.8045],\n",
      "        [ 1.2271, -1.3980,  1.3648],\n",
      "        [-0.3439, -0.3490, -0.1845],\n",
      "        [ 0.9314, -1.0427, -0.2660],\n",
      "        [-1.6444, -0.7975, -0.5241],\n",
      "        [-1.1393, -1.0675, -0.4113],\n",
      "        [ 0.5542, -0.7812,  0.8467],\n",
      "        [ 1.4799,  0.6455, -0.5353],\n",
      "        [ 1.1460,  0.8029,  1.8106],\n",
      "        [ 0.4462,  1.3766, -1.2718],\n",
      "        [-0.3623,  1.0443, -1.1626]])\n",
      "Raw masks:  tensor([[ 0.2424,  0.5468,  0.2108],\n",
      "        [-0.3485, -0.5059, -0.1457],\n",
      "        [-0.2767, -0.5192, -0.2042],\n",
      "        [ 0.3708, -0.4371, -0.1920],\n",
      "        [ 0.6924,  0.0128, -0.2949],\n",
      "        [-0.3701, -0.1067,  0.5232],\n",
      "        [-0.1512, -0.3842, -0.4646],\n",
      "        [ 0.0420, -0.2865, -0.6715],\n",
      "        [-0.2494, -0.6912, -0.0594],\n",
      "        [ 0.3739,  0.2004,  0.4257],\n",
      "        [ 0.3076, -0.3504,  0.3421],\n",
      "        [-0.3919, -0.3978, -0.2103],\n",
      "        [ 0.4158, -0.4655, -0.1188],\n",
      "        [-0.5544, -0.2689, -0.1767],\n",
      "        [-0.4351, -0.4077, -0.1571],\n",
      "        [ 0.2540, -0.3580,  0.3880],\n",
      "        [ 0.5562,  0.2426, -0.2012],\n",
      "        [ 0.3048,  0.2136,  0.4816],\n",
      "        [ 0.1442,  0.4448, -0.4110],\n",
      "        [-0.1410,  0.4065, -0.4525]])\n",
      "tensor(-3.7144)\n",
      "Masks:  tensor([[ 0.2424, -0.3485, -0.2767,  0.3708,  0.6924, -0.3701, -0.1512,  0.0420,\n",
      "         -0.2494,  0.3739,  0.3076, -0.3919,  0.4158, -0.5544, -0.4351,  0.2540,\n",
      "          0.5562,  0.3048,  0.1442, -0.1410],\n",
      "        [ 0.5468, -0.5059, -0.5192, -0.4371,  0.0128, -0.1067, -0.3842, -0.2865,\n",
      "         -0.6912,  0.2004, -0.3504, -0.3978, -0.4655, -0.2689, -0.4077, -0.3580,\n",
      "          0.2426,  0.2136,  0.4448,  0.4065],\n",
      "        [ 0.2108, -0.1457, -0.2042, -0.1920, -0.2949,  0.5232, -0.4646, -0.6715,\n",
      "         -0.0594,  0.4257,  0.3421, -0.2103, -0.1188, -0.1767, -0.1571,  0.3880,\n",
      "         -0.2012,  0.4816, -0.4110, -0.4525]])\n",
      "updated features:  tensor([[ 0.2424,  0.2424,  0.2424,  0.2424,  0.2424],\n",
      "        [-0.3485, -0.3485, -0.3485, -0.3485, -0.3485],\n",
      "        [-0.2767, -0.2767, -0.2767, -0.2767, -0.2767],\n",
      "        [ 0.3708,  0.3708,  0.3708,  0.3708,  0.3708],\n",
      "        [ 0.6924,  0.6924,  0.6924,  0.6924,  0.6924],\n",
      "        [-0.3701, -0.3701, -0.3701, -0.3701, -0.3701],\n",
      "        [-0.1512, -0.1512, -0.1512, -0.1512, -0.1512],\n",
      "        [ 0.0420,  0.0420,  0.0420,  0.0420,  0.0420],\n",
      "        [-0.2494, -0.2494, -0.2494, -0.2494, -0.2494],\n",
      "        [ 0.3739,  0.3739,  0.3739,  0.3739,  0.3739],\n",
      "        [ 0.3076,  0.3076,  0.3076,  0.3076,  0.3076],\n",
      "        [-0.3919, -0.3919, -0.3919, -0.3919, -0.3919],\n",
      "        [ 0.4158,  0.4158,  0.4158,  0.4158,  0.4158],\n",
      "        [-0.5544, -0.5544, -0.5544, -0.5544, -0.5544],\n",
      "        [-0.4351, -0.4351, -0.4351, -0.4351, -0.4351],\n",
      "        [ 0.2540,  0.2540,  0.2540,  0.2540,  0.2540],\n",
      "        [ 0.5562,  0.5562,  0.5562,  0.5562,  0.5562],\n",
      "        [ 0.3048,  0.3048,  0.3048,  0.3048,  0.3048],\n",
      "        [ 0.1442,  0.1442,  0.1442,  0.1442,  0.1442],\n",
      "        [-0.1410, -0.1410, -0.1410, -0.1410, -0.1410]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "mlp_output = torch.randn(20, 3)\n",
    "# raw_masks = F.softmax(mlp_output, dim=-1)\n",
    "print(\"MLP output: \", mlp_output)\n",
    "# print(\"MLP square: \", torch.abs(mlp_output))\n",
    "raw_masks = torch.nn.functional.normalize(mlp_output, p=1, dim=1)\n",
    "print(\"Raw masks: \", raw_masks)\n",
    "print(torch.sum(raw_masks))\n",
    "\n",
    "node_feature = torch.ones(20, 5)\n",
    "\n",
    "masks = torch.transpose(raw_masks, 0, 1)\n",
    "print(\"Masks: \", masks)\n",
    "updated_feature = torch.einsum('i,ij->ij', masks[0], node_feature)\n",
    "print(\"updated features: \", updated_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2673, 0.5345, 0.8018])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1,2,3])\n",
    "torch.nn.functional.normalize(a, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0000, -0.5828, -0.1285],\n",
      "        [ 2.0000, -0.1852,  1.4881],\n",
      "        [ 2.0000, -0.0696, -1.0252],\n",
      "        [ 2.0000, -0.2703,  0.5161],\n",
      "        [ 2.0000,  0.5234,  0.5290]])\n",
      "tensor([[ 0.4472, -0.6841, -0.0657],\n",
      "        [ 0.4472, -0.2173,  0.7606],\n",
      "        [ 0.4472, -0.0817, -0.5240],\n",
      "        [ 0.4472, -0.3173,  0.2638],\n",
      "        [ 0.4472,  0.6143,  0.2704]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(5, 3)\n",
    "for i in range(5):\n",
    "    a[i][0] = 2\n",
    "b = torch.nn.functional.normalize(a, dim=0)\n",
    "print(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
